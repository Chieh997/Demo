{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL(w5) DNN - Avoiding Overfitting / Transfer Learning\n",
    "student ID: 7110018036\\\n",
    "name: Chieh-An, Chou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoiding Overfitting \n",
    "### 1. Regularization\n",
    "增加 penalty term 限制 weight，避免其過大。\n",
    "+ $l_1$ regularization: $J'(\\theta)= J(\\theta)+\\alpha_1\\sum_{j=1}^n|w_j|$\n",
    "+ $l_2$ regularization: $J'(\\theta)= J(\\theta)+\\alpha_2\\sum_{j=1}^nw_j^2$\n",
    "+ Elastic net regularization: $J'(\\theta)= J(\\theta)+\\alpha_1\\sum_{j=1}^n|w_j|+\\alpha_2\\sum_{j=1}^nw_j^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L1',\n",
       " 'L1L2',\n",
       " 'L2',\n",
       " 'OrthogonalRegularizer',\n",
       " 'Regularizer',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'l1',\n",
       " 'l1_l2',\n",
       " 'l2',\n",
       " 'orthogonal_regularizer',\n",
       " 'serialize']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in dir(keras.regularizers) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_l1 = keras.regularizers.l1(l1= .01)\n",
    "r_l2 = keras.regularizers.l2(l2= .01)\n",
    "r_l1l2 = keras.regularizers.l1_l2(l1= .01, l2=.01)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(x_train_set, y_train_set), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_set, y_train_set, random_state = 1)\n",
    "\n",
    "# Preprocessing\n",
    "pixel_means = x_train.mean(axis=0, keepdims=True) # (N, 28,28) -> (1,28,28)\n",
    "pixel_stds = x_train.std(axis=0, keepdims=True)\n",
    "x_train_scaled = (x_train-pixel_means)/pixel_stds\n",
    "x_valid_scaled = (x_valid-pixel_means)/pixel_stds\n",
    "x_test_scaled = (x_test-pixel_means)/pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear and setting random seed\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_l2 = keras.regularizers.l2(l2= .01)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(units=300, activation='relu', kernel_initializer='he_normal', kernel_regularizer=r_l2), \n",
    "    keras.layers.Dense(units=100, activation='relu', kernel_initializer='he_normal', kernel_regularizer=r_l2),\n",
    "    keras.layers.Dense(units=10, activation='softmax', kernel_regularizer=r_l2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer='nadam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 0.7160 - accuracy: 0.8321 - val_loss: 0.7295 - val_accuracy: 0.8349\n",
      "Epoch 2/2\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 0.7005 - accuracy: 0.8352 - val_loss: 0.6861 - val_accuracy: 0.8415\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(x_train_scaled, y_train, epochs = 2,\n",
    "                  validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dropout(rate=.2), # Dropout layer\n",
    "    keras.layers.Dense(units=300, activation='relu', \n",
    "    kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(rate=.2),  \n",
    "    keras.layers.Dense(units=100, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(rate=.2), \n",
    "    keras.layers.Dense(units=10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer='nadam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.5745 - accuracy: 0.7957 - val_loss: 0.4074 - val_accuracy: 0.8513\n",
      "Epoch 2/2\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 0.4392 - accuracy: 0.8405 - val_loss: 0.3620 - val_accuracy: 0.8663\n"
     ]
    }
   ],
   "source": [
    "# 每次訓練隨機去除部分神經元\n",
    "train = model.fit(x_train_scaled, y_train, epochs = 2,\n",
    "                  validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 938us/step - loss: 0.3899 - accuracy: 0.8575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38988885283470154, 0.8575000166893005]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用所有神經元\n",
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 801us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.29, 0.  , 0.64],\n",
       "       [0.  , 0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用所有神經元\n",
    "y_proba = model.predict(x_test_scaled)\n",
    "y_proba[:3].round(2) # 樣本屬於各類別之機率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true = [9 2 1] , y_pred = [9 2 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(y_proba ,axis=1)\n",
    "print(f\"y_true = {y_test[:3]} , y_pred = {y_pred[:3]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Monte Carlo Dropout (MC Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict with Dropout multiple times\n",
    "y_probs = np.stack([model(x_test_scaled[:3], training = True) for _ in range(100)])\n",
    "y_probs.shape # 100 times predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.32, 0.  , 0.56],\n",
       "       [0.  , 0.  , 0.98, 0.  , 0.01, 0.  , 0.01, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob_mc = y_probs.mean(axis=0) # dim 0: 100 -> 1\n",
    "np.round(y_prob_mc, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true = [9 2 1] , y_pred = [9 2 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(y_proba ,axis=1)\n",
    "print(f\"y_true = {y_test[:3]} , y_pred = {y_pred[:3]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha Dropout\n",
    "`SELU` 需要標準化後的神經元，使用`AlphaDropout` 才能使剩下的(未被去除的)神經元滿足此條件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.AlphaDropout(rate=.2), # Alpha Dropout\n",
    "    keras.layers.Dense(units=300, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    # Layer with activation: SELU \n",
    "    keras.layers.AlphaDropout(rate=.2),\n",
    "    keras.layers.Dense(units=100, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.AlphaDropout(rate=.2),\n",
    "    keras.layers.Dense(units=10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer='nadam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1407/1407 [==============================] - 4s 2ms/step - loss: 0.6715 - accuracy: 0.7620 - val_loss: 0.6056 - val_accuracy: 0.8283\n",
      "Epoch 2/2\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.5084 - accuracy: 0.8112 - val_loss: 0.5309 - val_accuracy: 0.8431\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(x_train_scaled, y_train, epochs = 2,\n",
    "                  validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Max-Norm Regularization\n",
    "限制每一層的weights $\\|\\mathbf{w}\\|_2\\le r \\implies \\mathbf{w}\\leftarrow r\\dfrac{\\mathbf{w}}{\\|\\mathbf{w}\\|_2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.AlphaDropout(rate=.2), \n",
    "    keras.layers.Dense(units=300, activation='selu', \n",
    "                       kernel_initializer='lecun_normal',\n",
    "                       kernel_constraint = keras.constraints.max_norm(1.)), # max-norm regularization\n",
    "    keras.layers.AlphaDropout(rate=.2),\n",
    "    keras.layers.Dense(units=100, activation='selu',\n",
    "                        kernel_initializer='lecun_normal',\n",
    "                       kernel_constraint = keras.constraints.max_norm(1.)),\n",
    "    keras.layers.AlphaDropout(rate=.2),\n",
    "    keras.layers.Dense(units=10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer='nadam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1407/1407 [==============================] - 4s 2ms/step - loss: 0.6611 - accuracy: 0.7636 - val_loss: 46.7643 - val_accuracy: 0.6607\n",
      "Epoch 2/2\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.5167 - accuracy: 0.8081 - val_loss: 35.2071 - val_accuracy: 0.6633\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(x_train_scaled, y_train, epochs = 2,\n",
    "                  validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "步驟:\n",
    "1. 載入已存在模型\n",
    "2. 使用較低層(Reuse Lower Layers): trained\n",
    "3. 替換較高層(Replace Upper Layers): untrained\n",
    "4. 初期訓練(Train in the First Few Epochs)\n",
    "    + Upper Layers: `trainable = True`\n",
    "    + Lower Layers: `trainable = False`\n",
    "5. 後期訓練(Continue Training)\n",
    "    + Upper Layers: `trainable = True`\n",
    "    + Lower Layers: `trainable = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(x_train_set, y_train_set), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_set, y_train_set, random_state = 1)\n",
    "\n",
    "# Preprocessing\n",
    "x_train = x_train/255\n",
    "x_valid = x_valid/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into two part: coat-scandal & others\n",
    "def split_data(x,y):\n",
    "    idx_B = (y==4) | (y==5)\n",
    "    y_B = (y[idx_B] == 5).astype(np.float32) # 4 -> 0, 5 -> 1\n",
    "    y_A = y[~idx_B]\n",
    "    y_A[y_A > 5] -= 2\n",
    "    return (x[~idx_B], y_A), (x[idx_B], y_B)\n",
    "(x_train_A, y_train_A), (x_train_B, y_train_B) = split_data(x_train, y_train)\n",
    "(x_valid_A, y_valid_A), (x_valid_B, y_valid_B) = split_data(x_valid, y_valid)\n",
    "(x_test_A, y_test_A), (x_test_B, y_test_B) = split_data(x_test, y_test)\n",
    "\n",
    "x_train_B, y_train_B = x_train_B[:100], y_train_B[:100] # select 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset A:  (35968, 28, 28) [0 1 2 3 4 5 6 7]\n",
      "Dataset B:  (100, 28, 28) [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset A: \" , x_train_A.shape, np.unique(y_train_A))\n",
    "print(\"Dataset B: \" , x_train_B.shape, np.unique(y_train_B))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear and setting random seed\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "for hidden_i in (200, 150,100,50):\n",
    "    model_A.add(keras.layers.Dense(units=hidden_i, activation='relu'))\n",
    "model_A.add(keras.layers.Dense(units=8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               157000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               30150     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 408       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 207,708\n",
      "Trainable params: 207,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_A.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 1.5872 - accuracy: 0.5359 - val_loss: 1.0528 - val_accuracy: 0.7217\n",
      "Epoch 2/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.8116 - accuracy: 0.7740 - val_loss: 0.6590 - val_accuracy: 0.8030\n",
      "Epoch 3/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.5997 - accuracy: 0.8090 - val_loss: 0.5534 - val_accuracy: 0.8188\n",
      "Epoch 4/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.5275 - accuracy: 0.8219 - val_loss: 0.5045 - val_accuracy: 0.8266\n",
      "Epoch 5/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.4890 - accuracy: 0.8321 - val_loss: 0.4810 - val_accuracy: 0.8261\n",
      "Epoch 6/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.4633 - accuracy: 0.8412 - val_loss: 0.4540 - val_accuracy: 0.8438\n",
      "Epoch 7/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.4437 - accuracy: 0.8470 - val_loss: 0.4432 - val_accuracy: 0.8433\n",
      "Epoch 8/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.4282 - accuracy: 0.8533 - val_loss: 0.4238 - val_accuracy: 0.8501\n",
      "Epoch 9/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.4152 - accuracy: 0.8581 - val_loss: 0.4133 - val_accuracy: 0.8555\n",
      "Epoch 10/20\n",
      "1124/1124 [==============================] - 2s 2ms/step - loss: 0.4048 - accuracy: 0.8612 - val_loss: 0.4061 - val_accuracy: 0.8586\n",
      "Epoch 11/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.3951 - accuracy: 0.8652 - val_loss: 0.3944 - val_accuracy: 0.8603\n",
      "Epoch 12/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.3875 - accuracy: 0.8663 - val_loss: 0.3886 - val_accuracy: 0.8637\n",
      "Epoch 13/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.3807 - accuracy: 0.8687 - val_loss: 0.3817 - val_accuracy: 0.8666\n",
      "Epoch 14/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.3744 - accuracy: 0.8711 - val_loss: 0.3752 - val_accuracy: 0.8678\n",
      "Epoch 15/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.3689 - accuracy: 0.8724 - val_loss: 0.3752 - val_accuracy: 0.8688\n",
      "Epoch 16/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.3638 - accuracy: 0.8749 - val_loss: 0.3668 - val_accuracy: 0.8705\n",
      "Epoch 17/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.3591 - accuracy: 0.8755 - val_loss: 0.3637 - val_accuracy: 0.8699\n",
      "Epoch 18/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.3545 - accuracy: 0.8778 - val_loss: 0.3627 - val_accuracy: 0.8715\n",
      "Epoch 19/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.3508 - accuracy: 0.8794 - val_loss: 0.3677 - val_accuracy: 0.8673\n",
      "Epoch 20/20\n",
      "1124/1124 [==============================] - 3s 2ms/step - loss: 0.3467 - accuracy: 0.8812 - val_loss: 0.3527 - val_accuracy: 0.8743\n"
     ]
    }
   ],
   "source": [
    "train = model_A.fit(x_train_A, y_train_A, epochs = 20,\n",
    "                  validation_data=(x_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3799 - accuracy: 0.8669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37990137934684753, 0.8668749928474426]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A.evaluate(x_test_A, y_test_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save('model_A.h5') # save model_A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model B (Without Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "for hidden_i in (300, 150,100,80):\n",
    "    model_B.add(keras.layers.Dense(units=hidden_i, activation='relu'))\n",
    "model_B.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 150)               45150     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 80)                8080      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 303,911\n",
      "Trainable params: 303,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 90ms/step - loss: 0.6640 - accuracy: 0.6300 - val_loss: 0.6559 - val_accuracy: 0.6951\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.6566 - accuracy: 0.6400 - val_loss: 0.6485 - val_accuracy: 0.6944\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.6490 - accuracy: 0.6500 - val_loss: 0.6396 - val_accuracy: 0.6769\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.6398 - accuracy: 0.6600 - val_loss: 0.6297 - val_accuracy: 0.6590\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.6303 - accuracy: 0.6500 - val_loss: 0.6235 - val_accuracy: 0.6550\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.6235 - accuracy: 0.6300 - val_loss: 0.6171 - val_accuracy: 0.6513\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.6169 - accuracy: 0.6200 - val_loss: 0.6101 - val_accuracy: 0.6422\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.6097 - accuracy: 0.6100 - val_loss: 0.6035 - val_accuracy: 0.6311\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.6027 - accuracy: 0.5900 - val_loss: 0.5973 - val_accuracy: 0.6226\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.5963 - accuracy: 0.6000 - val_loss: 0.5916 - val_accuracy: 0.6166\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.5903 - accuracy: 0.5800 - val_loss: 0.5852 - val_accuracy: 0.6085\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.5839 - accuracy: 0.5800 - val_loss: 0.5808 - val_accuracy: 0.6102\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.5793 - accuracy: 0.5800 - val_loss: 0.5766 - val_accuracy: 0.6112\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.5748 - accuracy: 0.5800 - val_loss: 0.5713 - val_accuracy: 0.6044\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.5693 - accuracy: 0.5800 - val_loss: 0.5666 - val_accuracy: 0.6004\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.5645 - accuracy: 0.5800 - val_loss: 0.5629 - val_accuracy: 0.6021\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.5607 - accuracy: 0.5800 - val_loss: 0.5598 - val_accuracy: 0.6095\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.5573 - accuracy: 0.5800 - val_loss: 0.5561 - val_accuracy: 0.6146\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.5534 - accuracy: 0.5900 - val_loss: 0.5509 - val_accuracy: 0.6031\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.5480 - accuracy: 0.5800 - val_loss: 0.5471 - val_accuracy: 0.5997\n"
     ]
    }
   ],
   "source": [
    "train = model_B.fit(x_train_B, y_train_B, epochs = 20,\n",
    "                  validation_data=(x_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5432 - accuracy: 0.6090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5432047843933105, 0.609000027179718]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(x_test_B, y_test_B)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_tr (Transfer Learning)\n",
    "\n",
    "#### 1. Load model_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               157000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               30150     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 408       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 207,708\n",
      "Trainable params: 207,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_A = keras.models.load_model('model_A.h5')\n",
    "model_A.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Reuse Lower Layers\n",
    "保留 `flatten` - `dense_2`, 捨棄最後兩層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               157000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               30150     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               15100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 202,250\n",
      "Trainable params: 202,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_tr = keras.models.Sequential(model_A.layers[:-2])\n",
    "model_tr.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Replace Upper Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               157000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               30150     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 80)                8080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 210,411\n",
      "Trainable params: 210,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_tr.add(keras.layers.Dense(80, activation='relu'))\n",
    "model_tr.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model_tr.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Train in the First Few Epochs (epoch 1-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " flatten (Flatten)           (None, 784)               0         N          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 200)               157000    N          \n",
      "                                                                            \n",
      " dense_1 (Dense)             (None, 150)               30150     N          \n",
      "                                                                            \n",
      " dense_2 (Dense)             (None, 100)               15100     N          \n",
      "                                                                            \n",
      " dense_10 (Dense)            (None, 80)                8080      Y          \n",
      "                                                                            \n",
      " dense_11 (Dense)            (None, 1)                 81        Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 210,411\n",
      "Trainable params: 8,161\n",
      "Non-trainable params: 202,250\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in model_tr.layers[:-2]:\n",
    "    layer.trainable  = False # non-trianable lower layers\n",
    "model_tr.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tr.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "4/4 [==============================] - 1s 89ms/step - loss: 0.8792 - accuracy: 0.5200 - val_loss: 0.7524 - val_accuracy: 0.5135\n",
      "Epoch 2/4\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7097 - accuracy: 0.5700 - val_loss: 0.6347 - val_accuracy: 0.6894\n",
      "Epoch 3/4\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.6065 - accuracy: 0.6900 - val_loss: 0.5506 - val_accuracy: 0.8100\n",
      "Epoch 4/4\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.5313 - accuracy: 0.8200 - val_loss: 0.5025 - val_accuracy: 0.7972\n"
     ]
    }
   ],
   "source": [
    "train = model_tr.fit(x_train_B, y_train_B, epochs = 4,\n",
    "                  validation_data=(x_valid_B, y_valid_B))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Continue Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " flatten (Flatten)           (None, 784)               0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 200)               157000    Y          \n",
      "                                                                            \n",
      " dense_1 (Dense)             (None, 150)               30150     Y          \n",
      "                                                                            \n",
      " dense_2 (Dense)             (None, 100)               15100     Y          \n",
      "                                                                            \n",
      " dense_10 (Dense)            (None, 80)                8080      Y          \n",
      "                                                                            \n",
      " dense_11 (Dense)            (None, 1)                 81        Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 210,411\n",
      "Trainable params: 210,411\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in model_tr.layers[:-2]:\n",
    "    layer.trainable  = True # non-trianable lower layers\n",
    "model_tr.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tr.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "4/4 [==============================] - 1s 89ms/step - loss: 0.4811 - accuracy: 0.8300 - val_loss: 0.4634 - val_accuracy: 0.8507\n",
      "Epoch 2/16\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.4430 - accuracy: 0.8900 - val_loss: 0.4300 - val_accuracy: 0.8848\n",
      "Epoch 3/16\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.4108 - accuracy: 0.9200 - val_loss: 0.3992 - val_accuracy: 0.8956\n",
      "Epoch 4/16\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3804 - accuracy: 0.9200 - val_loss: 0.3760 - val_accuracy: 0.9009\n",
      "Epoch 5/16\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3587 - accuracy: 0.9200 - val_loss: 0.3549 - val_accuracy: 0.9356\n",
      "Epoch 6/16\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3367 - accuracy: 0.9400 - val_loss: 0.3363 - val_accuracy: 0.9542\n",
      "Epoch 7/16\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3186 - accuracy: 0.9400 - val_loss: 0.3195 - val_accuracy: 0.9609\n",
      "Epoch 8/16\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3025 - accuracy: 0.9500 - val_loss: 0.3064 - val_accuracy: 0.9734\n",
      "Epoch 9/16\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2888 - accuracy: 0.9700 - val_loss: 0.2922 - val_accuracy: 0.9751\n",
      "Epoch 10/16\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2749 - accuracy: 0.9800 - val_loss: 0.2811 - val_accuracy: 0.9794\n",
      "Epoch 11/16\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2641 - accuracy: 0.9800 - val_loss: 0.2710 - val_accuracy: 0.9801\n",
      "Epoch 12/16\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2538 - accuracy: 0.9800 - val_loss: 0.2603 - val_accuracy: 0.9845\n",
      "Epoch 13/16\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2435 - accuracy: 0.9800 - val_loss: 0.2503 - val_accuracy: 0.9869\n",
      "Epoch 14/16\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2338 - accuracy: 0.9800 - val_loss: 0.2422 - val_accuracy: 0.9865\n",
      "Epoch 15/16\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2255 - accuracy: 0.9800 - val_loss: 0.2343 - val_accuracy: 0.9875\n",
      "Epoch 16/16\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2178 - accuracy: 0.9800 - val_loss: 0.2262 - val_accuracy: 0.9882\n"
     ]
    }
   ],
   "source": [
    "train = model_tr.fit(x_train_B, y_train_B, epochs = 16,\n",
    "                  validation_data=(x_valid_B, y_valid_B))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison: model_tr vs model_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22385764122009277, 0.9904999732971191]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tr.evaluate(x_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.6090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5432047843933105, 0.609000027179718]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(x_test_B, y_test_B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
